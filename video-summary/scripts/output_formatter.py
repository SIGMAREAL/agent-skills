#!/usr/bin/env python3
"""
è¾“å‡ºæ ¼å¼åŒ–æ¨¡å—

æŒ‰ç…§ OUTPUT_FORMAT.md è§„èŒƒç”Ÿæˆç»Ÿä¸€çš„ Markdown è¾“å‡ºã€‚
"""

import sys
import re
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional
from urllib.parse import urlparse

# å¯¼å…¥è´¨é‡è¯„åˆ†å™¨
sys.path.insert(0, str(Path(__file__).parent))
from quality_scorer import calculate_quality_score


# é¢„å®šä¹‰å†…å®¹ç±»å‹
CONTENT_TYPES = {
    "tutorial": "æ•™ç¨‹/æ•™å­¦",
    "news": "æ–°é—»/èµ„è®¯",
    "analysis": "åˆ†æ/æ·±åº¦æŠ¥é“",
    "interview": "é‡‡è®¿/å¯¹è¯",
    "research": "ç ”ç©¶/è®ºæ–‡",
    "opinion": "è§‚ç‚¹/è¯„è®º",
    "review": "äº§å“/å†…å®¹è¯„æµ‹",
    "other": "å…¶ä»–",
}

# é¢„å®šä¹‰æ ‡ç­¾
PREDEFINED_TAGS = [
    "AI/æœºå™¨å­¦ä¹ ",
    "ç¼–ç¨‹/å¼€å‘",
    "äº§å“/è®¾è®¡",
    "å•†ä¸š/åˆ›ä¸š",
    "é‡‘è/æŠ•èµ„",
    "ç§‘æŠ€/æ•°ç ",
    "ç”Ÿæ´»/å¥åº·",
    "å¿ƒç†/æˆé•¿",
    "æ—¶äº‹/æ–°é—»",
    "å…¶ä»–",
]

# å¹³å°æ£€æµ‹
PLATFORM_MAP = {
    "youtube.com": "YouTube",
    "youtu.be": "YouTube",
    "bilibili.com": "Bç«™",
    "b23.tv": "Bç«™",
    "twitter.com": "Twitter",
    "x.com": "Twitter",
    "weixin.qq.com": "å…¬ä¼—å·",
    "mp.weixin.qq.com": "å…¬ä¼—å·",
    "zhihu.com": "çŸ¥ä¹",
    "juejin.cn": "æ˜é‡‘",
    "jianshu.com": "ç®€ä¹¦",
    "csdn.net": "CSDN",
    "medium.com": "Medium",
    "github.com": "GitHub",
}


def sanitize_filename(text: str, max_length: int = 50) -> str:
    """
    æ¸…ç†æ–‡ä»¶åï¼Œç§»é™¤ä¸å®‰å…¨å­—ç¬¦

    è§„åˆ™ï¼š
    - `/` `\` `:` `*` `?` `"` `<` `>` `|` â†’ æ›¿æ¢ä¸º `-`
    - ç©ºæ ¼ â†’ æ›¿æ¢ä¸º `-`
    - è¿ç»­ `-` â†’ åˆå¹¶ä¸ºä¸€ä¸ª
    - é™åˆ¶é•¿åº¦
    """
    # æ›¿æ¢ä¸å®‰å…¨å­—ç¬¦
    text = re.sub(r'[/\\:*?"<>|]', '-', text)
    text = re.sub(r'\s+', '-', text)
    text = re.sub(r'-{2,}', '-', text)
    text = text.strip('-')

    # æˆªæ–­
    if len(text) > max_length:
        text = text[:max_length].rsplit('-', 1)[0]

    return text or "æœªå‘½å"


def detect_platform(url: str) -> str:
    """æ£€æµ‹å¹³å°"""
    url_lower = url.lower()
    for domain, platform in PLATFORM_MAP.items():
        if domain in url_lower:
            return platform
    return "å…¶ä»–"


def detect_language(text: str) -> str:
    """æ£€æµ‹æ–‡æœ¬è¯­è¨€"""
    chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', text))
    total_chars = len(text)

    if total_chars == 0:
        return "unknown"

    chinese_ratio = chinese_chars / total_chars

    if chinese_ratio > 0.3:
        return "zh"
    elif chinese_ratio > 0.05:
        return "mixed"
    else:
        return "en"


def translate_title_to_zh(title: str) -> str:
    """
    ç¿»è¯‘æ ‡é¢˜ä¸ºä¸­æ–‡

    æ³¨æ„ï¼šè¿™æ˜¯å ä½ç¬¦å‡½æ•°ï¼Œå®é™…ç¿»è¯‘ç”± Claude å®Œæˆ
    è¿™é‡Œåªåšç®€å•å¤„ç†ï¼šè¿”å›åŸæ ‡é¢˜ï¼Œç”± Claude åç»­ç¿»è¯‘
    """
    # å¦‚æœæ ‡é¢˜åŒ…å«ä¸­æ–‡å­—ç¬¦ï¼Œè®¤ä¸ºå·²ç»æ˜¯ä¸­æ–‡
    if re.search(r'[\u4e00-\u9fff]', title):
        return title

    # å¦åˆ™è¿”å›åŸæ ‡é¢˜ï¼Œç­‰å¾… Claude ç¿»è¯‘
    return title


def generate_filename(
    title: str,
    author: str,
    type_zh: str,
    platform: str,
    date: str
) -> str:
    """
    ç”Ÿæˆæ–‡ä»¶å

    æ ¼å¼: {ä½œè€…}_{ä¸­æ–‡æ ‡é¢˜}_ã€{ç±»å‹}ã€‘{å¹³å°}-{æ—¥æœŸ}.md
    å¦‚æœæ²¡æœ‰æ—¥æœŸï¼Œæ ¼å¼ä¸º: {ä½œè€…}_{ä¸­æ–‡æ ‡é¢˜}_ã€{ç±»å‹}ã€‘{å¹³å°}.md
    """
    # æ¸…ç†å„éƒ¨åˆ†
    title_clean = sanitize_filename(title, max_length=50)
    author_clean = sanitize_filename(author, max_length=20) if author else ""

    # ç»„è£…
    if author_clean:
        if date:
            filename = f"{author_clean}_{title_clean}_ã€{type_zh}ã€‘{platform}-{date}.md"
        else:
            filename = f"{author_clean}_{title_clean}_ã€{type_zh}ã€‘{platform}.md"
    else:
        if date:
            filename = f"{title_clean}_ã€{type_zh}ã€‘{platform}-{date}.md"
        else:
            filename = f"{title_clean}_ã€{type_zh}ã€‘{platform}.md"

    return filename


def generate_frontmatter(
    title: str,
    url: str,
    author: str,
    platform: str,
    source: str,
    publish_date: Optional[str],
    extracted_date: str,
    content_type: str,
    language: str,
    duration: Optional[str],
    transcript: str,
) -> Dict[str, Any]:
    """
    ç”Ÿæˆ YAML frontmatter æ•°æ®
    """
    # è®¡ç®—ä¿¡æ¯è´¨é‡åˆ†
    quality_result = calculate_quality_score(transcript)

    # âš ï¸ æ—¥æœŸè§„åˆ™ï¼šç»ä¸è‡ªåŠ¨ç”¨ extracted_date å¡«å…… publish_date
    # publish_date å¿…é¡»ä» API æˆ–é¡µé¢å…ƒæ•°æ®è·å–
    # å¦‚æœè·å–ä¸åˆ°ï¼Œä¿æŒä¸º None æˆ–ç©ºå­—ç¬¦ä¸²

    # è¯­è¨€æ£€æµ‹
    if not language or language == "unknown":
        language = detect_language(transcript)

    frontmatter = {
        "title": title,
        "title_zh": "",  # ç”± Claude å¡«å……
        "author": author or "",
        "platform": platform,
        "source": source or platform,
        "url": url,
        "publish_date": publish_date or "",  # ä¿æŒä¸ºç©ºï¼Œä¸è‡ªåŠ¨å¡«å……
        "extracted_date": extracted_date,
        "type": content_type,
        "language": language,
        "duration": duration or "",
        "word_count": quality_result["word_count"],
        "quality_score": quality_result["score"],
        "tags": [],  # ç”± Claude é€‰æ‹©
    }

    return frontmatter


def frontmatter_to_yaml(data: Dict[str, Any]) -> str:
    """å°†å­—å…¸è½¬æ¢ä¸º YAML frontmatter æ ¼å¼"""
    lines = ["---"]

    for key, value in data.items():
        if isinstance(value, list):
            if value:
                # åˆ—è¡¨æ ¼å¼
                items = ', '.join(f'"{v}"' for v in value)
                lines.append(f"{key}: [{items}]")
            else:
                lines.append(f"{key}: []")
        elif isinstance(value, bool):
            lines.append(f"{key}: {'true' if value else 'false'}")
        elif value is None or value == "":
            lines.append(f"{key}: ")
        else:
            lines.append(f"{key}: {value}")

    lines.append("---")
    return "\n".join(lines)


def generate_markdown(
    title: str,
    url: str,
    author: str,
    platform: str,
    source: str,
    publish_date: Optional[str],
    transcript: str,
    content_type: str = "other",
    language: str = "zh",
    duration: Optional[str] = None,
    description: str = "",
) -> tuple[str, Dict[str, Any]]:
    """
    ç”Ÿæˆå®Œæ•´çš„ Markdown å†…å®¹

    è¿”å›: (markdown_content, frontmatter_data)
    """
    now = datetime.now()
    extracted_date = now.strftime("%Y-%m-%d")

    # ç”Ÿæˆ frontmatter
    frontmatter_data = generate_frontmatter(
        title=title,
        url=url,
        author=author,
        platform=platform,
        source=source,
        publish_date=publish_date,
        extracted_date=extracted_date,
        content_type=content_type,
        language=language,
        duration=duration,
        transcript=transcript,
    )

    # ç±»å‹ä¸­æ–‡
    type_zh = CONTENT_TYPES.get(content_type, "å…¶ä»–")

    # ç”Ÿæˆæ–‡ä»¶å
    title_zh = frontmatter_data["title_zh"] or translate_title_to_zh(title)
    date_for_filename = frontmatter_data["publish_date"]

    filename = generate_filename(
        title=title_zh,
        author=author,
        type_zh=type_zh,
        platform=platform,
        date=date_for_filename,
    )

    # ä¿¡æ¯è´¨é‡åˆ†
    qs = frontmatter_data["quality_score"]

    # ç”Ÿæˆå†…å®¹
    yaml_str = frontmatter_to_yaml(frontmatter_data)

    content = f"""{yaml_str}

# {title}

## ğŸ“Š ä¿¡æ¯æ¦‚è§ˆ

| å±æ€§ | å€¼ |
|------|-----|
| ç±»å‹ | {type_zh} |
| å¹³å° | {platform} |
| ä½œè€… | {author or '-'} |
| å‘å¸ƒæ—¥æœŸ | {frontmatter_data['publish_date']} |
| ä¿¡æ¯è´¨é‡ | {qs}/100 |

> [åŸå§‹é“¾æ¥]({url})

---

## ğŸ“ å…¥é—¨çº§æ€»ç»“ï¼ˆå°ç™½å‹å¥½ï¼‰

{{CLAUDE_BEGINNER_SUMMARY_PLACEHOLDER}}

---

## ğŸ“ æ ‡å‡†çº§æ€»ç»“

{{CLAUDE_STANDARD_SUMMARY_PLACEHOLDER}}

---

## ğŸ“ æ·±å…¥çº§æ€»ç»“ï¼ˆä¸“ä¸šç‰ˆï¼‰

{{CLAUDE_EXPERT_SUMMARY_PLACEHOLDER}}

---

## ğŸ“„ ä¸­æ–‡å…¨æ–‡

{{CLAUDE_FULLTEXT_PLACEHOLDER}}

---

## ğŸ“‹ åŸå§‹å†…å®¹

{transcript}

---

*æå–æ—¶é—´: {now.strftime("%Y-%m-%d %H:%M")} | ä¿¡æ¯è´¨é‡åˆ†: {qs}/100*
"""

    return content, frontmatter_data


def save_markdown(
    content: str,
    filename: str,
    output_dir: Path,
) -> Path:
    """ä¿å­˜ Markdown æ–‡ä»¶"""
    output_path = output_dir / filename
    output_path.write_text(content, encoding="utf-8")
    return output_path


if __name__ == "__main__":
    # æµ‹è¯•
    test_title = "Deep Learning Tutorial for Beginners"
    test_url = "https://youtube.com/watch?v=test"
    test_author = "AI Expert"
    test_transcript = "è¿™æ˜¯ä¸€ä¸ªå…³äºæ·±åº¦å­¦ä¹ çš„æ•™ç¨‹ã€‚æ·±åº¦å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„é‡è¦åˆ†æ”¯ã€‚ç¥ç»ç½‘ç»œæ˜¯å…¶æ ¸å¿ƒã€‚"

    content, fm = generate_markdown(
        title=test_title,
        url=test_url,
        author=test_author,
        platform="YouTube",
        source="YouTube",
        publish_date="2025-12-25",
        transcript=test_transcript,
        content_type="tutorial",
    )

    print(content)
    print("\n=== Filename ===")
    print(generate_filename(
        title="æ·±åº¦å­¦ä¹ å…¥é—¨",
        author="æå®æ¯…",
        type_zh="æ•™ç¨‹",
        platform="YouTube",
        date="2025-12-25",
    ))
