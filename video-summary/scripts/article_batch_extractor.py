#!/usr/bin/env python3
"""
æ–‡ç« æ‰¹é‡æå–å™¨ - é˜²å°é”ç‰ˆæœ¬
æ”¯æŒ Jina Reader å’Œ browser-use åŒæ¨¡å¼
"""

import os
import json
import re
import time
import random
import subprocess
from pathlib import Path
from datetime import datetime
from typing import List, Optional
import sys
import requests

# æ‰¹é‡æå–é…ç½®
BATCH_CONFIG = {
    "delay_between_requests": 3,  # è¯·æ±‚é—´ç­‰å¾…ç§’æ•°
    "max_retries": 3,
    "retry_delay": 30,  # é‡è¯•ç­‰å¾…ç§’æ•°
    "session_file": "~/.cache/article_extractor/session.json",
}

class ArticleBatchExtractor:
    def __init__(self, output_dir: str = "~/Documents/articles"):
        self.output_dir = Path(output_dir).expanduser()
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.cache_dir = Path("~/.cache/article_extractor").expanduser()
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        self.session_file = self.cache_dir / "session.json"
        self.load_session()

        # Jina Reader é…ç½®
        self.jina_base = "https://r.jina.ai/"

        # è¯·æ±‚å¤´ï¼ˆæ¨¡æ‹Ÿæµè§ˆå™¨ï¼‰
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36"
        }

    def load_session(self):
        """åŠ è½½ä¼šè¯çŠ¶æ€"""
        if self.session_file.exists():
            self.session = json.loads(self.session_file.read_text())
        else:
            self.session = {
                "last_extracted": None,
                "blocked": False,
                "block_until": None,
                "rate_limit_count": 0,
            }

    def save_session(self):
        """ä¿å­˜ä¼šè¯çŠ¶æ€"""
        self.session_file.write_text(json.dumps(self.session, indent=2))

    def is_blocked(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦è¢«å°é”"""
        if self.session.get("blocked") and self.session.get("block_until"):
            if datetime.now().timestamp() < self.session.get("block_until", 0):
                return True
        return False

    def set_blocked(self, duration: int = 180):
        """æ ‡è®°è¢«å°é”ï¼ˆé»˜è®¤ 3 åˆ†é’Ÿï¼‰"""
        self.session["blocked"] = True
        self.session["block_until"] = datetime.now().timestamp() + duration
        self.session["rate_limit_count"] = self.session.get("rate_limit_count", 0) + 1
        self.save_session()

    def clear_block(self):
        """è§£é™¤å°é”çŠ¶æ€"""
        self.session["blocked"] = False
        self.session["block_until"] = None
        self.save_session()

    def extract_jina(self, url: str) -> Optional[str]:
        """ç”¨ Jina Reader æå–"""
        # æ£€æŸ¥å°é”çŠ¶æ€
        if self.is_blocked():
            wait_time = self.session.get("block_until", 0) - datetime.now().timestamp()
            if wait_time > 0:
                print(f"â³ é™æµä¸­ï¼Œç­‰å¾… {wait_time:.0f} ç§’...")
                time.sleep(min(wait_time, 180))
                self.clear_block()

        # éšæœºå»¶è¿Ÿï¼ˆ2-5 ç§’ï¼‰
        delay = random.uniform(2, 5)
        time.sleep(delay)

        try:
            response = requests.get(f"{self.jina_base}{url}", headers=self.headers, timeout=30)

            # æ£€æŸ¥é™æµ
            if response.status_code == 429:
                print(f"âš ï¸ è§¦å‘é™æµ (429)")
                self.set_blocked(duration=60)
                return None

            if response.status_code == 503:
                print(f"âš ï¸ æœåŠ¡ä¸å¯ç”¨ (503)")
                self.set_blocked(duration=30)
                return None

            if response.status_code == 200:
                self.clear_block()
                content = response.text

                # æ£€æŸ¥æ˜¯å¦æ˜¯éªŒè¯ç é¡µé¢
                if "captcha" in content.lower() or "cloudflare" in content.lower():
                    print(f"âš ï¸ æ£€æµ‹åˆ°éªŒè¯ç ")
                    self.set_blocked(duration=120)
                    return None

                return content

            return None

        except Exception as e:
            print(f"âŒ è¯·æ±‚å¤±è´¥: {e}")
            return None

    def extract_browser_use(self, url: str) -> Optional[str]:
        """ç”¨ browser-use æå–ï¼ˆåçˆ¬ç½‘ç«™å¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        try:
            # æ‰“å¼€é¡µé¢
            result = subprocess.run(
                ["browser-use", "open", url],
                capture_output=True, text=True, timeout=60
            )

            if result.returncode != 0:
                return None

            # ç­‰å¾…åŠ è½½
            time.sleep(random.uniform(3, 6))

            # æå–å†…å®¹ï¼ˆé’ˆå¯¹ä¸åŒç½‘ç«™é€‰æ‹©ä¸åŒé€‰æ‹©å™¨ï¼‰
            selectors = [
                "document.body.innerText",  # é€šç”¨
                "document.getElementById('js_content')?.innerText",  # å¾®ä¿¡å…¬ä¼—å·
                "document.querySelector('article')?.innerText",  # Twitter/X
            ]

            for selector in selectors:
                eval_result = subprocess.run(
                    ["browser-use", "eval", selector],
                    capture_output=True, text=True, timeout=30
                )
                if eval_result.returncode == 0 and eval_result.stdout:
                    return eval_result.stdout

            return None

        except Exception as e:
            print(f"âŒ browser-use å¤±è´¥: {e}")
            return None

    def detect_domain(self, url: str) -> str:
        """æ£€æµ‹åŸŸåç±»å‹"""
        url_lower = url.lower()

        if "twitter.com" in url_lower or "x.com" in url_lower:
            return "twitter"
        elif "mp.weixin.qq.com" in url_lower:
            return "wechat"
        elif "youtube.com" in url_lower or "youtu.be" in url_lower:
            return "youtube"
        elif "bilibili.com" in url_lower:
            return "bilibili"
        else:
            return "general"

    def extract(self, url: str, method: str = "auto") -> Optional[str]:
        """æå–å•ç¯‡æ–‡ç« """
        domain = self.detect_domain(url)

        # è‡ªåŠ¨é€‰æ‹©æ–¹æ³•
        if method == "auto":
            if domain == "wechat":
                # å¾®ä¿¡å…¬ä¼—å·å¿…é¡»ç”¨ browser-use
                method = "browser"
            elif domain in ["twitter", "general"]:
                # Twitter å’Œé€šç”¨ç½‘é¡µä¼˜å…ˆ Jina Reader
                method = "jina"
            else:
                method = "jina"

        # æ‰§è¡Œæå–
        if method == "jina":
            content = self.extract_jina(url)
            # å¦‚æœ Jina å¤±è´¥ï¼Œé™çº§åˆ° browser-use
            if not content:
                print(f"ğŸ”„ Jina å¤±è´¥ï¼Œå°è¯• browser-use...")
                content = self.extract_browser_use(url)
        else:
            content = self.extract_browser_use(url)

        return content

    def batch_extract(self, urls: List[str], method: str = "auto") -> dict:
        """æ‰¹é‡æå–"""
        results = {}
        today = datetime.now().strftime("%Y-%m-%d")
        output_subdir = self.output_dir / today
        output_subdir.mkdir(parents=True, exist_ok=True)

        for i, url in enumerate(urls):
            print(f"\n[{i+1}/{len(urls)}] {url}")

            # æ£€æŸ¥å°é”
            if self.is_blocked() and method == "jina":
                wait = self.session.get("block_until", 0) - datetime.now().timestamp()
                print(f"â³ ç­‰å¾… {wait:.0f} ç§’...")
                time.sleep(min(wait, 300))
                self.clear_block()

            # æå–
            content = self.extract(url, method=method)

            if content and len(content) > 100:
                # ç”Ÿæˆæ–‡ä»¶å
                domain = self.detect_domain(url)
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"{timestamp}_{domain}_{random.randint(1000, 9999)}.md"
                filepath = output_subdir / filename

                # ç”Ÿæˆæ­£ç¡®æ ¼å¼çš„ Markdownï¼ˆå¸¦ frontmatter å’Œå ä½ç¬¦ï¼‰
                title = url.split('/')[-1].replace('-', ' ').title()
                safe_title = re.sub(r'[^a-zA-Z0-9\s]', '', title)[:50].replace(' ', '-')

                # æå–ç¬¬ä¸€è¡Œä½œä¸ºæ ‡é¢˜ï¼ˆå¦‚æœ content ä»¥ # å¼€å¤´ï¼‰
                content_lines = content.split('\n')
                if content_lines and content_lines[0].startswith('#'):
                    extracted_title = content_lines[0].lstrip('#').strip()
                else:
                    extracted_title = title

                safe_title = re.sub(r'[^a-zA-Z0-9\-]', '', extracted_title)[:50]
                now_str = datetime.now().strftime("%Y-%m-%d %H:%M")
                now_date = datetime.now().strftime("%Y-%m-%d")

                full_content = f'''---
title: {extracted_title}
source: letters.thedankoe.com
url: {url}
date: {now_date}
type: article
language: original
---

# {extracted_title}

> **æ¥æº**: [letters.thedankoe.com]({url})
> **æå–æ—¥æœŸ**: {now_str}

---

## ğŸ“ ä¸­æ–‡æç‚¼æ€»ç»“

{{CLAUDE_SUMMARY_PLACEHOLDER}}

---

## ä¸­æ–‡å…¨æ–‡

{{CLAUDE_FULLTEXT_PLACEHOLDER}}

---

## åŸå§‹å†…å®¹

{content}

---

*Claude Content Extractor æå– | {now_str}*
'''

                filepath.write_text(full_content, encoding='utf-8')

                results[url] = {
                    "success": True,
                    "file": str(filepath),
                    "content_length": len(content),
                    "extracted_at": datetime.now().isoformat()
                }
                print(f"  âœ… æˆåŠŸ ({len(content)} å­—ç¬¦) â†’ {filename}")
            else:
                results[url] = {
                    "success": False,
                    "error": "æå–å¤±è´¥æˆ–å†…å®¹è¿‡çŸ­"
                }
                print(f"  âŒ å¤±è´¥")

            # ä¿å­˜è¿›åº¦
            self.save_session()

            # è¯·æ±‚é—´éšæœºå»¶è¿Ÿï¼ˆ2-5 ç§’ï¼‰
            if i < len(urls) - 1:
                delay = random.uniform(2, 5)
                print(f"â³ ç­‰å¾… {delay:.0f} ç§’...")
                time.sleep(delay)

        # ä¿å­˜æ‰¹é‡ç»“æœæ‘˜è¦
        summary_file = output_subdir / f"batch_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        summary_file.write_text(json.dumps(results, indent=2, ensure_ascii=False))

        print(f"\nğŸ’¾ æ‰¹é‡æ‘˜è¦ä¿å­˜åˆ°: {summary_file}")

        return results


def batch_extract_from_file(input_file: str, method: str = "auto"):
    """ä»æ–‡ä»¶æ‰¹é‡æå–"""
    extractor = ArticleBatchExtractor()

    # è¯»å– URL åˆ—è¡¨
    urls = [line.strip() for line in Path(input_file).read_text().split('\n') if line.strip()]

    print(f"ğŸ“‹ å¼€å§‹æ‰¹é‡æå– {len(urls)} ä¸ªæ–‡ç« ...")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {extractor.output_dir}")
    print(f"ğŸ”§ æå–æ–¹æ³•: {method}")

    results = extractor.batch_extract(urls, method=method)

    # ç»Ÿè®¡
    success_count = sum(1 for r in results.values() if r.get("success"))
    print(f"\nğŸ“Š å®Œæˆ: {success_count}/{len(urls)} æˆåŠŸ")

    return results


if __name__ == "__main__":
    if len(sys.argv) > 1:
        method = sys.argv[2] if len(sys.argv) > 2 else "auto"
        batch_extract_from_file(sys.argv[1], method=method)
    else:
        print("ç”¨æ³•: python article_batch_extractor.py <urls.txt> [method]")
        print("method: auto (é»˜è®¤), jina, browser")
        print("")
        print("ç¤ºä¾‹:")
        print("  python article_batch_extractor.py urls.txt")
        print("  python article_batch_extractor.py urls.txt jina")
        print("  python article_batch_extractor.py urls.txt browser")
